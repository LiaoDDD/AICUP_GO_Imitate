{"cells":[{"cell_type":"code","execution_count":1,"id":"bb173248","metadata":{"executionInfo":{"elapsed":11342,"status":"ok","timestamp":1697462358428,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"bb173248"},"outputs":[],"source":["import tensorflow as tf\n","from keras.applications import ResNet50\n","from keras.models import Model\n","from keras.layers import Input, Conv2D, Flatten,  Softmax, BatchNormalization, MaxPooling2D, ELU, Dense, ReLU, Dropout\n","from keras.layers import Add, GlobalAveragePooling2D\n","from keras.optimizers import Adam\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras import regularizers\n"]},{"cell_type":"code","execution_count":2,"id":"50b384f7","metadata":{},"outputs":[{"data":{"text/plain":["'2.10.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"markdown","id":"bd95ed0c","metadata":{"id":"bd95ed0c"},"source":["# Data Pre-Processing\n","\n","Open **dan_train.csv** file and split the games into a list.\n","Every row of csv: `DL0000000001,B,B[pd],W[dp],B[pp],W[dc],B[de],...`.\n","\n","Columns are:\n","\n","    1. DL0000000001: Game ID\n","    2. B: Player's color\n","    3-... : Moves\n","    \n","We cropped only the moves to game list as:"]},{"cell_type":"code","execution_count":3,"id":"2f8872fd","metadata":{"executionInfo":{"elapsed":1335,"status":"ok","timestamp":1697462362134,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"2f8872fd"},"outputs":[],"source":["df = open(\"C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/dan_train.csv\").read().splitlines()\n","games = [i.split(',',2)[-1] for i in df]"]},{"cell_type":"markdown","id":"58532b01","metadata":{"id":"58532b01"},"source":["Create a dictionary to convert the coordinates from characters to numbers"]},{"cell_type":"code","execution_count":2,"id":"496585f2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697462362135,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"496585f2","outputId":"70e52802-f9ad-42aa-d7b7-253972db5daf"},"outputs":[{"data":{"text/plain":["{'a': 0,\n"," 'b': 1,\n"," 'c': 2,\n"," 'd': 3,\n"," 'e': 4,\n"," 'f': 5,\n"," 'g': 6,\n"," 'h': 7,\n"," 'i': 8,\n"," 'j': 9,\n"," 'k': 10,\n"," 'l': 11,\n"," 'm': 12,\n"," 'n': 13,\n"," 'o': 14,\n"," 'p': 15,\n"," 'q': 16,\n"," 'r': 17,\n"," 's': 18}"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["chars = 'abcdefghijklmnopqrs'\n","coordinates = {k:v for v,k in enumerate(chars)}\n","chartonumbers = {k:v for k,v in enumerate(chars)}\n","coordinates"]},{"cell_type":"markdown","id":"92277370","metadata":{"id":"92277370"},"source":["We decided to build a DCNN model in this tutorial. We create data samples by using every move in every game, meaning that the target is to predict the next move by feeding the previous state of the table in every game for every move. Therefore, we can collect much more data samples from games.\n","\n","For the simplicity, we used 4 dimensional feature map to represent the data as below:\n"," 1. Positions of black stones: mark them as 1 and the rest of the table as 0\n"," 2. Positions of white stones: mark them as 1 and the rest of the table as 0\n"," 3. Empty areas of the table: mark the empty areas as 1 and occupied areas as 0\n"," 4. The last move in the table: mark the position of the last move as 1 and the rest as 0\n","\n","Target value is a number between 0-361(19\\*19). Later this will be one-hot encoded."]},{"cell_type":"code","execution_count":3,"id":"0adb423c","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697462362135,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"0adb423c"},"outputs":[],"source":["def extract_features(moves):\n","    features = np.zeros((19, 19, 11))\n","\n","    for i, move in enumerate(moves):\n","        color = move[0]\n","        column = coordinates[move[2]]\n","        row = coordinates[move[3]]\n","\n","        features[row, column, 0] = 1 if color == 'W' else -1  # 表示下棋的顏色\n","        features[row, column, 1] = 1 if i % 2 == 0 else -1  # 表示輪到哪一方下棋\n","        features[row, column, 2] = 1  # 表示該位置上是否已下棋\n","\n","        # 最後一步的信息\n","        features[row, column, 3] = 1 if i == len(moves) - 1 else 0\n","\n","        # 最近幾步的分佈情況\n","        for j in range(1, min(5, i + 1)):\n","            prev_move = moves[i - j]\n","            prev_column = coordinates[prev_move[2]]\n","            prev_row = coordinates[prev_move[3]]\n","            features[prev_row, prev_column, j] = 1 if prev_move[0] == color else -1\n","        \n","    # 其他特徵的計算...\n","    # 這裡可以添加更多特徵的計算邏輯，例如區域控制、連子信息等\n","\n","    return features\n","\n","\n","def prepare_input(moves):\n","    x = np.zeros((19, 19, 11))\n","\n","    # 在這裡調用特徵提取函數\n","    features = extract_features(moves)\n","\n","    # 將提取的特徵放入輸入張量的特定通道\n","    x[:, :, 0:5] = features[:, :, 0:5]\n","\n","    # 其他通道的處理...\n","    # 例如，你可以在不同的通道上添加其他特徵\n","\n","    # 將你原本的邏輯放在這裡...\n","\n","        \n","\n","    if moves:\n","        last_move_column = coordinates[moves[-1][2]]\n","        last_move_row = coordinates[moves[-1][3]]\n","        x[last_move_row, last_move_column, 3] = 1\n","\n","    x[:, :, 2] = np.where(x[:, :, 2] == 0, 1, 0)\n","\n","    return x\n","\n","def prepare_label(move):\n","    column = coordinates[move[2]]\n","    row = coordinates[move[3]]\n","    return column*19+row"]},{"cell_type":"code","execution_count":6,"id":"758808ae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2913,"status":"ok","timestamp":1697462365044,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"758808ae","outputId":"f173cdb6-a4e3-44f0-c73f-8334394e8f1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Games: 100160, Total Moves: 22853380\n"]}],"source":["# Check how many samples can be obtained\n","n_games = 0\n","n_moves = 0\n","for game in games:\n","    n_games += 1\n","    moves_list = game.split(',')\n","    for move in moves_list:\n","        n_moves += 1\n","print(f\"Total Games: {n_games}, Total Moves: {n_moves}\")"]},{"cell_type":"markdown","id":"46403360","metadata":{"id":"46403360"},"source":["The code below is run for baseline model only by using only the first 500 games from the dataset. You might need to create a data generator to use complete dataset. Otherwise your RAM might not enough to store all (If you run the code on free version of Google Colab, it will crash above 500 game samples)."]},{"cell_type":"code","execution_count":7,"id":"a9bb0ab0","metadata":{"executionInfo":{"elapsed":12119,"status":"ok","timestamp":1697462377150,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"a9bb0ab0"},"outputs":[],"source":["import random\n","\n","\n","x = []\n","y = []\n","games = random.sample(games, 2000)\n","for game in games:\n","    moves_list = game.split(',')\n","    for count, move in enumerate(moves_list):\n","        x.append(prepare_input(moves_list[:count]))\n","        y.append(prepare_label(moves_list[count]))\n","x = np.array(x)\n","y = np.array(y)"]},{"cell_type":"code","execution_count":8,"id":"5b2392a4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1697462377150,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"5b2392a4","outputId":"e33bd430-9c7c-42fe-f25c-590d42479cb6"},"outputs":[{"data":{"text/plain":["(456269, 19, 19, 11)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x.shape"]},{"cell_type":"code","execution_count":9,"id":"73521b4f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1697462377150,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"73521b4f","outputId":"804a693f-1f5f-4e9c-ddcb-a5ed6b0b204b"},"outputs":[{"data":{"text/plain":["(456269,)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["y.shape"]},{"cell_type":"code","execution_count":10,"id":"5510a7a6","metadata":{"executionInfo":{"elapsed":2166,"status":"ok","timestamp":1697462379870,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"5510a7a6"},"outputs":[],"source":["y_one_hot = tf.one_hot(y, depth=19*19)"]},{"cell_type":"markdown","id":"78b048ff","metadata":{"id":"78b048ff"},"source":["Dataset splitting: 90% Training, 10% validation"]},{"cell_type":"code","execution_count":11,"id":"3f594acb","metadata":{"executionInfo":{"elapsed":1089,"status":"ok","timestamp":1697462380956,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"3f594acb"},"outputs":[],"source":["x_train, x_val, y_train, y_val = train_test_split(x, y_one_hot.numpy(), test_size=0.10)"]},{"cell_type":"code","execution_count":null,"id":"fe49be87","metadata":{},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Average\n","\n","def create_model1():\n","    inputs = Input(shape=(19, 19, 11))\n","    outputs = Conv2D(kernel_size=12, filters=64, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(inputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=16, filters=32, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=16, filters=32, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=16, filters=32, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=16, filters=1, padding='same', activation='relu',kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","\n","    outputs = Flatten()(outputs)\n","    outputs = Softmax()(outputs)\n","    outputs = Dropout(0.05)(outputs)\n","\n","    model = Model(inputs, outputs)\n","\n","    opt = Adam(learning_rate=0.001)\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","\n","# Create an ensemble model using Average and Lambda layers\n","models = [create_model1() for i in range(5)]\n","model_input = Input(shape=(19, 19, 11))\n","model_outputs = [model(model_input) for model in models]\n","ensemble_output = Average()(model_outputs)\n","ensemble_model = Model(inputs=model_input, outputs=ensemble_output)\n","ensemble_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"7b9c5de9","metadata":{"id":"7b9c5de9"},"source":["# Training\n","\n","### Simple DCNN Model:"]},{"cell_type":"code","execution_count":null,"id":"208834da","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1697462380956,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"208834da"},"outputs":[],"source":["def create_model():\n","    inputs = Input(shape=(19, 19, 11))\n","\n","    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    x = BatchNormalization()(x)\n","\n","    x = Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Conv2D(kernel_size=3, filters=256, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","\n","    \n","    x = Conv2D(kernel_size=3, filters=512, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","\n","    x = Flatten()(x)\n","    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    x = Dense(361, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    outputs = Dense(361, activation='softmax')(x)\n","\n","    model = Model(inputs, outputs)\n","\n","    opt = Adam(learning_rate=0.0005)\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n"]},{"cell_type":"code","execution_count":12,"id":"cae75cc6","metadata":{},"outputs":[],"source":["def create_model6():\n","    inputs = Input(shape=(19, 19, 11))\n","    outputs = Conv2D(kernel_size=7, filters=64, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(inputs)\n","    outputs = BatchNormalization()(outputs)\n","    \n","    outputs = Conv2D(kernel_size=5, filters=64, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    \n","    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=5, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    outputs = Conv2D(kernel_size=16, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","   \n","    outputs = Conv2D(kernel_size=16, filters=32, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","   \n","    outputs = Conv2D(kernel_size=16, filters=1, padding='same', activation='relu', kernel_regularizer= regularizers.l2(0.003))(outputs)\n","    outputs = BatchNormalization()(outputs)\n","\n","    outputs = ELU()(outputs)\n","    outputs = Flatten()(outputs)\n","    outputs = Softmax()(outputs)\n","    \n","    model = Model(inputs, outputs)\n","\n","    opt = Adam(learning_rate=0.001)\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"258462bf","metadata":{},"outputs":[],"source":["def create_model7():\n","    inputs = Input(shape=(19, 19, 11))\n","\n","    x = Conv2D(kernel_size=3, filters=64, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(kernel_size=3, filters=128, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Conv2D(kernel_size=3, filters=256, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = GlobalAveragePooling2D()(x)\n","\n","    x = Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.5)(x)\n","\n","    outputs = Dense(361, activation='sigmoid')(x)\n","\n","    model = Model(inputs, outputs)\n","\n","    opt = Adam(learning_rate=0.0005)\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"74918295","metadata":{},"outputs":[],"source":["from keras.models import Sequential\n","def create_model5():\n","    model = Sequential()\n","\n","    model.add(Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.003), input_shape=(19, 19, 11)))\n","    model.add(BatchNormalization())\n","\n","    model.add(Conv2D(kernel_size=3, filters=128, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.003)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=2))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(kernel_size=3, filters=256, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.003)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=2))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(kernel_size=3, filters=512, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.003)))\n","    model.add(BatchNormalization())\n","    model.add(MaxPooling2D(pool_size=2))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(361, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dropout(0.5))\n","\n","    model.add(Dense(361, activation='softmax'))\n","\n","    opt = Adam(learning_rate=0.0005)\n","    model.compile(optimizer=opt,\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"2a66e90d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697462380956,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"2a66e90d","outputId":"f2967ca8-ac8c-495f-c4c2-39d6fc6240bf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"id":"f2b86ece","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 19, 19, 11)]      0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 19, 19, 64)        34560     \n","                                                                 \n"," batch_normalization (BatchN  (None, 19, 19, 64)       256       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 19, 19, 64)        102464    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 19, 19, 64)       256       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 19, 19, 32)        51232     \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 19, 19, 32)        25632     \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 19, 19, 32)        9248      \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 19, 19, 32)        9248      \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 19, 19, 32)        9248      \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 19, 19, 32)        9248      \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 19, 19, 32)        262176    \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 19, 19, 32)        262176    \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 19, 19, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 19, 19, 1)         8193      \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 19, 19, 1)        4         \n"," chNormalization)                                                \n","                                                                 \n"," elu (ELU)                   (None, 19, 19, 1)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 361)               0         \n","                                                                 \n"," softmax (Softmax)           (None, 361)               0         \n","                                                                 \n","=================================================================\n","Total params: 784,965\n","Trainable params: 784,195\n","Non-trainable params: 770\n","_________________________________________________________________\n"]}],"source":["model6 = create_model6()\n","model6.summary()"]},{"cell_type":"code","execution_count":null,"id":"e678d58a","metadata":{},"outputs":[],"source":["ensemble_model.summary()"]},{"cell_type":"code","execution_count":4,"id":"c4e07612","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","1 Physical GPUs, 1 Logical GPU\n"]}],"source":["import tensorflow as tf\n","gpus = tf.config.list_physical_devices('GPU')\n","print(gpus)\n","if gpus:\n","    \n","    # Restrict TensorFlow to only use the first GPU\n","    try:\n","        tf.config.set_visible_devices(gpus[0], 'GPU')\n","        logical_gpus = tf.config.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n","    except RuntimeError as e:\n","        # Visible devices must be set before GPUs have been initialized\n","        print(e)"]},{"cell_type":"code","execution_count":null,"id":"a69d87ea","metadata":{},"outputs":[],"source":["history = ensemble_model.fit(\n","    x = x_train,\n","    y = y_train,\n","    batch_size = 256,\n","    epochs = 20,\n","    validation_data=(x_val, y_val),\n",")"]},{"cell_type":"code","execution_count":15,"id":"4a4d7f1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267252,"status":"ok","timestamp":1697462648205,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"4a4d7f1c","outputId":"9323b9b5-a70f-42a2-96b8-a6346ad42ec8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","802/802 [==============================] - 144s 147ms/step - loss: 4.8243 - accuracy: 0.1047 - val_loss: 4.1346 - val_accuracy: 0.2473\n","Epoch 2/40\n","802/802 [==============================] - 116s 145ms/step - loss: 3.5493 - accuracy: 0.3283 - val_loss: 3.5237 - val_accuracy: 0.3466\n","Epoch 3/40\n","802/802 [==============================] - 118s 147ms/step - loss: 3.2054 - accuracy: 0.3709 - val_loss: 3.2639 - val_accuracy: 0.3760\n","Epoch 4/40\n","802/802 [==============================] - 114s 143ms/step - loss: 3.0698 - accuracy: 0.3844 - val_loss: 3.1176 - val_accuracy: 0.3787\n","Epoch 5/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.9978 - accuracy: 0.3913 - val_loss: 3.1384 - val_accuracy: 0.3619\n","Epoch 6/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.9484 - accuracy: 0.3959 - val_loss: 3.0215 - val_accuracy: 0.3836\n","Epoch 7/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.9116 - accuracy: 0.3992 - val_loss: 3.0742 - val_accuracy: 0.3786\n","Epoch 8/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.8781 - accuracy: 0.4009 - val_loss: 2.9498 - val_accuracy: 0.3923\n","Epoch 9/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.8498 - accuracy: 0.4033 - val_loss: 2.9355 - val_accuracy: 0.3949\n","Epoch 10/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.8273 - accuracy: 0.4054 - val_loss: 2.9066 - val_accuracy: 0.3965\n","Epoch 11/40\n","802/802 [==============================] - 116s 145ms/step - loss: 2.8065 - accuracy: 0.4067 - val_loss: 2.8688 - val_accuracy: 0.4006\n","Epoch 12/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.7874 - accuracy: 0.4085 - val_loss: 2.8719 - val_accuracy: 0.4007\n","Epoch 13/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.7680 - accuracy: 0.4101 - val_loss: 2.8325 - val_accuracy: 0.4062\n","Epoch 14/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.7566 - accuracy: 0.4111 - val_loss: 2.8442 - val_accuracy: 0.3999\n","Epoch 15/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.7463 - accuracy: 0.4117 - val_loss: 2.8454 - val_accuracy: 0.3987\n","Epoch 16/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.7352 - accuracy: 0.4135 - val_loss: 2.8210 - val_accuracy: 0.3998\n","Epoch 17/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.7291 - accuracy: 0.4136 - val_loss: 2.8241 - val_accuracy: 0.4000\n","Epoch 18/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.7195 - accuracy: 0.4148 - val_loss: 2.8142 - val_accuracy: 0.4003\n","Epoch 19/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.7138 - accuracy: 0.4146 - val_loss: 2.7842 - val_accuracy: 0.3994\n","Epoch 20/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.7045 - accuracy: 0.4155 - val_loss: 2.7913 - val_accuracy: 0.4023\n","Epoch 21/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6978 - accuracy: 0.4157 - val_loss: 2.7996 - val_accuracy: 0.4036\n","Epoch 22/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6954 - accuracy: 0.4171 - val_loss: 2.8277 - val_accuracy: 0.4003\n","Epoch 23/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6900 - accuracy: 0.4171 - val_loss: 2.9048 - val_accuracy: 0.3953\n","Epoch 24/40\n","802/802 [==============================] - 116s 145ms/step - loss: 2.6868 - accuracy: 0.4175 - val_loss: 2.8462 - val_accuracy: 0.3998\n","Epoch 25/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6803 - accuracy: 0.4181 - val_loss: 2.8169 - val_accuracy: 0.4014\n","Epoch 26/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6781 - accuracy: 0.4172 - val_loss: 2.7956 - val_accuracy: 0.4059\n","Epoch 27/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6719 - accuracy: 0.4183 - val_loss: 2.8157 - val_accuracy: 0.4056\n","Epoch 28/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6729 - accuracy: 0.4185 - val_loss: 2.7707 - val_accuracy: 0.4069\n","Epoch 29/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6692 - accuracy: 0.4182 - val_loss: 2.8019 - val_accuracy: 0.4030\n","Epoch 30/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6676 - accuracy: 0.4191 - val_loss: 2.7627 - val_accuracy: 0.4050\n","Epoch 31/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.6627 - accuracy: 0.4185 - val_loss: 2.7873 - val_accuracy: 0.4042\n","Epoch 32/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.6608 - accuracy: 0.4190 - val_loss: 2.7831 - val_accuracy: 0.4014\n","Epoch 33/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.6546 - accuracy: 0.4195 - val_loss: 2.8088 - val_accuracy: 0.4020\n","Epoch 34/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6532 - accuracy: 0.4202 - val_loss: 2.7949 - val_accuracy: 0.4028\n","Epoch 35/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.6487 - accuracy: 0.4197 - val_loss: 2.7731 - val_accuracy: 0.3999\n","Epoch 36/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.6474 - accuracy: 0.4208 - val_loss: 2.7515 - val_accuracy: 0.4049\n","Epoch 37/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.6438 - accuracy: 0.4207 - val_loss: 2.7452 - val_accuracy: 0.4050\n","Epoch 38/40\n","802/802 [==============================] - 115s 143ms/step - loss: 2.6421 - accuracy: 0.4207 - val_loss: 2.7218 - val_accuracy: 0.4111\n","Epoch 39/40\n","802/802 [==============================] - 114s 143ms/step - loss: 2.6374 - accuracy: 0.4209 - val_loss: 2.7305 - val_accuracy: 0.4093\n","Epoch 40/40\n","802/802 [==============================] - 114s 142ms/step - loss: 2.6356 - accuracy: 0.4214 - val_loss: 2.8104 - val_accuracy: 0.3996\n"]}],"source":["def data_generator(x, y, batch_size):\n","    while True:\n","        for batch_start in range(0, len(x), batch_size):\n","            batch_end = batch_start + batch_size\n","            x_batch = x[batch_start:batch_end]\n","            y_batch = y[batch_start:batch_end]\n","            yield x_batch, y_batch\n","\n","# 創建生成器\n","batch_size = 512  # 設置合適的批次大小\n","train_generator = data_generator(x_train, y_train, batch_size)\n","val_generator = data_generator(x_val, y_val, batch_size)\n","\n","history = model6.fit(\n","    train_generator,\n","    steps_per_epoch=len(x_train)//batch_size,\n","    epochs=40,\n","    validation_data=val_generator,\n","    validation_steps=len(x_val)//batch_size\n",")"]},{"cell_type":"code","execution_count":16,"id":"2aaddf0b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1697462648524,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"2aaddf0b","outputId":"5d2004ba-8c63-4b56-cf0c-ee2d41eccfd9"},"outputs":[],"source":["model6.save('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial7.h5')"]},{"cell_type":"code","execution_count":null,"id":"b101f27a","metadata":{},"outputs":[],"source":["def data_generator(x, y, batch_size):\n","    while True:\n","        for batch_start in range(0, len(x), batch_size):\n","            batch_end = batch_start + batch_size\n","            x_batch = x[batch_start:batch_end]\n","            y_batch = y[batch_start:batch_end]\n","            yield x_batch, y_batch\n","\n","# 創建生成器\n","batch_size = 256  # 設置合適的批次大小\n","train_generator = data_generator(x_train, y_train, batch_size)\n","val_generator = data_generator(x_val, y_val, batch_size)\n","\n","history2 = model2.fit(\n","    train_generator,\n","    steps_per_epoch=len(x_train)//batch_size,\n","    epochs=10,\n","    validation_data=val_generator,\n","    validation_steps=len(x_val)//batch_size\n",")"]},{"cell_type":"code","execution_count":null,"id":"51842923","metadata":{},"outputs":[],"source":["model2.save('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial2.h5')"]},{"cell_type":"code","execution_count":null,"id":"3a1a5801","metadata":{},"outputs":[],"source":["def data_generator(x, y, batch_size):\n","    while True:\n","        for batch_start in range(0, len(x), batch_size):\n","            batch_end = batch_start + batch_size\n","            x_batch = x[batch_start:batch_end]\n","            y_batch = y[batch_start:batch_end]\n","            yield x_batch, y_batch\n","\n","# 創建生成器\n","batch_size = 256  # 設置合適的批次大小\n","train_generator = data_generator(x_train, y_train, batch_size)\n","val_generator = data_generator(x_val, y_val, batch_size)\n","\n","history3 = model3.fit(\n","    train_generator,\n","    steps_per_epoch=len(x_train)//batch_size,\n","    epochs=10,\n","    validation_data=val_generator,\n","    validation_steps=len(x_val)//batch_size\n",")"]},{"cell_type":"code","execution_count":null,"id":"1cc6681e","metadata":{},"outputs":[],"source":["model3.save('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial3.h5')"]},{"cell_type":"code","execution_count":18,"id":"6689b18b","metadata":{},"outputs":[{"ename":"InternalError","evalue":"Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Tidera\\github\\AICUP_GO_Imitate\\AICUP_GO_Imitate\\Dan Training Tutorial.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tidera/github/AICUP_GO_Imitate/AICUP_GO_Imitate/Dan%20Training%20Tutorial.ipynb#X45sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loaded_model_7 \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mC:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial7.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tidera/github/AICUP_GO_Imitate/AICUP_GO_Imitate/Dan%20Training%20Tutorial.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# 使用載入的模型進行預測\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tidera/github/AICUP_GO_Imitate/AICUP_GO_Imitate/Dan%20Training%20Tutorial.ipynb#X45sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pred_probs_model1 \u001b[39m=\u001b[39m loaded_model_1\u001b[39m.\u001b[39;49mpredict(x_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tidera/github/AICUP_GO_Imitate/AICUP_GO_Imitate/Dan%20Training%20Tutorial.ipynb#X45sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m pred_probs_model2 \u001b[39m=\u001b[39m loaded_model_2\u001b[39m.\u001b[39mpredict(x_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tidera/github/AICUP_GO_Imitate/AICUP_GO_Imitate/Dan%20Training%20Tutorial.ipynb#X45sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m pred_probs_model3 \u001b[39m=\u001b[39m loaded_model_3\u001b[39m.\u001b[39mpredict(x_val)\n","File \u001b[1;32mc:\\Users\\Tidera\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\Tidera\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["from keras.models import load_model\n","from sklearn.metrics import accuracy_score\n","\n","# 載入模型\n","loaded_model_1 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial.h5')\n","loaded_model_2 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial2.h5')\n","loaded_model_3 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial3.h5')\n","loaded_model_4 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial4.h5')\n","loaded_model_5 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial5.h5')\n","loaded_model_6 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial6.h5')\n","loaded_model_7 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial7.h5')\n","\n","# 使用載入的模型進行預測\n","pred_probs_model1 = loaded_model_1.predict(x_val)\n","pred_probs_model2 = loaded_model_2.predict(x_val)\n","pred_probs_model3 = loaded_model_3.predict(x_val)\n","pred_probs_model4 = loaded_model_4.predict(x_val)\n","pred_probs_model5 = loaded_model_5.predict(x_val)\n","pred_probs_model6 = loaded_model_6.predict(x_val)\n","pred_probs_model7 = loaded_model_7.predict(x_val)\n","\n","# 投票法 Ensemble\n","def ensemble_voting(pred_probs_list):\n","    final_predictions = []\n","    for i in range(len(pred_probs_list[0])):\n","        votes = [pred_probs[i].argmax() for pred_probs in pred_probs_list]\n","        #votes = [pred_probs[i] for pred_probs in pred_probs_list]\n","        final_predictions.append([max(set(votes), key=votes.count)])\n","        #average_vote = np.mean(votes, axis=0)\n","        #final_predictions.append([votes])\n","      \n","    return final_predictions\n","\n","# 將模型預測機率組成的列表傳入投票法\n","final_predictions = ensemble_voting([pred_probs_model1, pred_probs_model2, pred_probs_model3, pred_probs_model4, pred_probs_model5, pred_probs_model6,pred_probs_model7])\n","\n","# 將 y_val 轉換為單一標籤形式\n","y_val_single_label = y_val.argmax(axis=1)\n","\n","# 計算 Ensemble 後的準確率\n","accuracy = accuracy_score(y_val_single_label, final_predictions)\n","print(\"Ensemble Accuracy:\", accuracy)"]},{"cell_type":"markdown","id":"484be28d","metadata":{"id":"484be28d"},"source":["# Testing\n","\n","**PublicUpload.csv** must be in the following form:\n","```\n","DTPU0000000001,id,qr,pq,pd,ab\n","DTPU0000000002,ao,ab,ha,ff,qd\n","DTPU0000000003,qd,gd,fh,ed,fa\n","DTPU0000000004,pr,ba,dq,hh,aj\n","DTPU0000000005,ph,jh,af,df,gj\n","```\n","\n","- Column 1: Game ID\n","- Column 2: Predicted Moves, up to 5 predictions for each game\n","\n","The code block below is to use **dan_test_public.csv** to predict and save the results in required form. It generates the best 5 predictions for each sample and convert them to character coordinates."]},{"cell_type":"code","execution_count":5,"id":"2168612e","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697462648525,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"2168612e"},"outputs":[],"source":["def number_to_char(number):\n","    number_1, number_2 = divmod(number, 19)\n","    return chartonumbers[number_1] + chartonumbers[number_2]\n","\n","def top_5_preds_with_chars(predictions):\n","    resulting_preds_numbers = [np.flip(np.argpartition(prediction, -5)[-5:]) for prediction in predictions]\n","    resulting_preds_chars = np.vectorize(number_to_char)(resulting_preds_numbers)\n","    return resulting_preds_chars"]},{"cell_type":"code","execution_count":6,"id":"18e776de","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3792,"status":"ok","timestamp":1697462652315,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"18e776de","outputId":"0b938bc4-3b0b-4298-d950-f00c8dcc4cfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["344/344 [==============================] - 15s 35ms/step\n","344/344 [==============================] - 2s 6ms/step\n","344/344 [==============================] - 1s 2ms/step\n","344/344 [==============================] - 2s 5ms/step\n","344/344 [==============================] - 1s 2ms/step\n","344/344 [==============================] - 2s 6ms/step\n","344/344 [==============================] - 2s 6ms/step\n"]}],"source":["from keras.models import load_model\n","\n","df = open('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/dan_test_public.csv').read().splitlines()\n","games_id = [i.split(',',2)[0] for i in df]\n","games = [i.split(',',2)[-1] for i in df]\n","\n","\n","# 投票法 Ensemble\n","def ensemble_voting(pred_probs_list):\n","    final_predictions = []\n","    for i in range(len(pred_probs_list[0])):\n","        #votes = [pred_probs[i].argmax() for pred_probs in pred_probs_list]\n","        votes = [pred_probs[i] for pred_probs in pred_probs_list]\n","        #final_predictions.append([max(set(votes), key=votes.count)])\n","        average_vote = np.mean(votes, axis=0)\n","        final_predictions.append(average_vote)\n","    return final_predictions\n","\n","x_testing = []\n","\n","for game in games:\n","    moves_list = game.split(',')\n","    x_testing.append(prepare_input(moves_list))\n","\n","x_testing = np.array(x_testing)\n","\n","# 載入模型\n","loaded_model_1 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial.h5')\n","loaded_model_2 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial2.h5')\n","loaded_model_3 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial3.h5')\n","loaded_model_4 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial4.h5')\n","loaded_model_5 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial5.h5')\n","loaded_model_6 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial6.h5')\n","loaded_model_7 = load_model('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/model_dan_tutorial7.h5')\n","\n","pred_probs_model1 = loaded_model_1.predict(x_testing)\n","pred_probs_model2 = loaded_model_2.predict(x_testing)\n","pred_probs_model3 = loaded_model_3.predict(x_testing)\n","pred_probs_model4 = loaded_model_4.predict(x_testing)\n","pred_probs_model5 = loaded_model_5.predict(x_testing)\n","pred_probs_model6 = loaded_model_6.predict(x_testing)\n","pred_probs_model7 = loaded_model_7.predict(x_testing)\n","\n","predictions = ensemble_voting([pred_probs_model1, pred_probs_model2, pred_probs_model3, pred_probs_model4, pred_probs_model5, pred_probs_model6, pred_probs_model7])\n","prediction_chars = top_5_preds_with_chars(predictions)\n","\n","\n","# Save results to PublicUpload.csv\n","with open('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/PublicUpload1128-3.csv','a') as f:\n","    for index in range(len(prediction_chars)):\n","        answer_row = games_id[index] + ',' + ','.join(prediction_chars[index]) + '\\n'\n","        f.write(answer_row)"]},{"cell_type":"code","execution_count":7,"id":"6a03c3e1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["344/344 [==============================] - 12s 36ms/step\n","344/344 [==============================] - 2s 6ms/step\n","344/344 [==============================] - 1s 2ms/step\n","344/344 [==============================] - 2s 5ms/step\n","344/344 [==============================] - 1s 2ms/step\n","344/344 [==============================] - 2s 6ms/step\n","344/344 [==============================] - 2s 6ms/step\n"]}],"source":["df = open('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/dan_test_private.csv').read().splitlines()\n","games_id = [i.split(',',2)[0] for i in df]\n","games = [i.split(',',2)[-1] for i in df]\n","\n","x_testing = []\n","\n","for game in games:\n","    moves_list = game.split(',')\n","    x_testing.append(prepare_input(moves_list))\n","\n","x_testing = np.array(x_testing)\n","\n","pred_probs_model1 = loaded_model_1.predict(x_testing)\n","pred_probs_model2 = loaded_model_2.predict(x_testing)\n","pred_probs_model3 = loaded_model_3.predict(x_testing)\n","pred_probs_model4 = loaded_model_4.predict(x_testing)\n","pred_probs_model5 = loaded_model_5.predict(x_testing)\n","pred_probs_model6 = loaded_model_6.predict(x_testing)\n","pred_probs_model7 = loaded_model_7.predict(x_testing)\n","\n","predictions = final_predictions = ensemble_voting([pred_probs_model1, pred_probs_model2, pred_probs_model3, pred_probs_model4])\n","prediction_chars = top_5_preds_with_chars(predictions)\n","\n","\n","# Save results to PublicUpload.csv\n","with open('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/PublicUpload1128-3.csv','a') as f:\n","    for index in range(len(prediction_chars)):\n","        answer_row = games_id[index] + ',' + ','.join(prediction_chars[index]) + '\\n'\n","        f.write(answer_row)"]},{"cell_type":"markdown","id":"2f7fafaa","metadata":{"id":"2f7fafaa"},"source":["# End of Tutorial\n","\n","You are free to use more modern NN architectures, a better pre-processing, feature extraction methods to achieve much better accuracy!"]},{"cell_type":"code","execution_count":null,"id":"050b4672","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697462652315,"user":{"displayName":"Ting Yang Lu (アズーサ)","userId":"17219646350901583040"},"user_tz":-480},"id":"050b4672","outputId":"472034f1-2e7b-4dd7-972f-bf5614b43209"},"outputs":[],"source":["print(prediction_chars)"]},{"cell_type":"code","execution_count":null,"id":"cf7fe45c","metadata":{},"outputs":[],"source":["df = open('C:/Users/Tidera/Downloads/drive-download-20231017T013717Z-001/PublicUpload-1127.csv').read().splitlines()\n","games = [i.split(',')[0] for i in df]\n","games"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.11"}},"nbformat":4,"nbformat_minor":5}
